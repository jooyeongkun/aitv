import re

with open('ai_service_fixed.py', 'r', encoding='utf-8') as f:
    content = f.read()

# Add greeting detection method
greeting_method = '''
    def is_greeting(self, user_message):
        """ì¸ì‚¬ë§ ì²´í¬"""
        greetings = ['ì•ˆë…•í•˜ì„¸ìš”', 'ì•ˆë…•', 'hi', 'hello', 'í—¬ë¡œ', 'í•˜ì´']
        return any(greeting in user_message.lower().strip() for greeting in greetings)
    '''

# Insert after __init__ method
content = content.replace('def extract_keywords(self, user_message):', 
                         greeting_method + '\n    def extract_keywords(self, user_message):')

# Update generate_response method
old_generate = '''def generate_response(self, user_message, hotels, tours):
        """AI ì‘ë‹µ ìƒì„±"""
        try:
            # ì»¨í…ìŠ¤íŠ¸ ì¤€ë¹„
            context = f"ì‚¬ìš©ì ì§ˆë¬¸: {user_message}\n\n"'''

new_generate = '''def generate_response(self, user_message, hotels, tours):
        """AI ì‘ë‹µ ìƒì„±"""
        try:
            # ì¸ì‚¬ë§ ì²˜ë¦¬
            if self.is_greeting(user_message):
                return "ì•ˆë…•í•˜ì„¸ìš”! ğŸ˜Š ì—¬í–‰ ìƒë‹´ì‚¬ì…ë‹ˆë‹¤. ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”? ì°¾ìœ¼ì‹œëŠ” í˜¸í…” ì •ë³´ë‚˜ íˆ¬ì–´ê°€ ìˆìœ¼ì‹ ê°€ìš”?"
            
            # ì»¨í…ìŠ¤íŠ¸ ì¤€ë¹„
            context = f"ì‚¬ìš©ì ì§ˆë¬¸: {user_message}\n\n"'''

content = content.replace(old_generate, new_generate)

# Update API call to use Gemini
old_api = '''# OpenAI API í˜¸ì¶œ
            response = self.client.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=[
                    {
                        "role": "system", 
                        "content": """ë‹¹ì‹ ì€ ì—¬í–‰ ìƒë‹´ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì£¼ì–´ì§„ í˜¸í…”/íˆ¬ì–´ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ê³ ê°ì˜ ì§ˆë¬¸ì— ë‹µë³€í•˜ì„¸ìš”.

ê·œì¹™:
1. ì˜¤ì§ ì œê³µëœ ë°ì´í„°ë² ì´ìŠ¤ ì •ë³´ë§Œ ì‚¬ìš©í•˜ì„¸ìš”
2. ë¬´ì¡°ê±´ì ì¸ ì¶”ì²œì€ í•˜ì§€ ë§ˆì„¸ìš”
3. ê³ ê°ì˜ ì§ˆë¬¸ ì˜ë„ë¥¼ íŒŒì•…í•˜ê³  ê´€ë ¨ ì •ë³´ë§Œ ì œê³µí•˜ì„¸ìš”
4. ì •í™•í•œ ê°€ê²©ê³¼ ì •ë³´ë¥¼ ì œê³µí•˜ì„¸ìš”
5. ì¹œê·¼í•˜ê³  ì „ë¬¸ì ì¸ í†¤ì„ ì‚¬ìš©í•˜ì„¸ìš”
6. ë°ì´í„°ì— ì—†ëŠ” ë‚´ìš©ì€ "í•´ë‹¹ ì •ë³´ë¥¼ í™•ì¸í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤"ë¼ê³  ì•ˆë‚´í•˜ì„¸ìš”"""
                    },
                    {
                        "role": "user",
                        "content": context
                    }
                ],
                max_tokens=500,
                temperature=0.7
            )
            
            return response.choices[0].message.content.strip()'''

new_api = '''# Google Gemini API í˜¸ì¶œ
            prompt = f"""ë‹¹ì‹ ì€ ì¹œê·¼í•œ ì—¬í–‰ ìƒë‹´ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì£¼ì–´ì§„ í˜¸í…”/íˆ¬ì–´ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ê³ ê°ì˜ ì§ˆë¬¸ì— ë‹µë³€í•˜ì„¸ìš”.

ê·œì¹™:
1. ì˜¤ì§ ì œê³µëœ ë°ì´í„°ë² ì´ìŠ¤ ì •ë³´ë§Œ ì‚¬ìš©í•˜ì„¸ìš”
2. ì¹œê·¼í•˜ê³  ë”°ëœ»í•œ í†¤ìœ¼ë¡œ ì‘ë‹µí•˜ì„¸ìš”
3. ì •í™•í•œ ê°€ê²©ê³¼ ì •ë³´ë¥¼ ì œê³µí•˜ì„¸ìš”
4. ì´ëª¨ì§€ë¥¼ ì ì ˆíˆ ì‚¬ìš©í•˜ì—¬ ì¹œê·¼í•¨ì„ í‘œí˜„í•˜ì„¸ìš”

{context}"""

            response = self.model.generate_content(prompt)
            return response.text.strip()'''

content = content.replace(old_api, new_api)

with open('ai_service_fixed.py', 'w', encoding='utf-8') as f:
    f.write(content)
